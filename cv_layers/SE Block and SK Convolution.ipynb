{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/linukc/master_dlcourse/blob/main/class_3/notebook_class_3_part1.ipynb","timestamp":1678119542447}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["План семинара **\"Реализация собственных операторов на языке Python в фреймворке Pytorch\"**\n","1. [Squeeze-and-Excitation (SE) Block](https://arxiv.org/abs/1709.01507)\n","2. [Selective Kernel (SK) Convolution](https://arxiv.org/abs/1903.06586)"],"metadata":{"id":"vtKLj3EjRVAT"}},{"cell_type":"markdown","source":["# Squeeze-and-Excitation (SE) Block"],"metadata":{"id":"w_AuOxMxTb-5"}},{"cell_type":"markdown","source":["“Squeeze-and-Excitation” (SE) block can adaptively recalibrates\n","channel-wise feature responses by explicitly modelling interdependencies between channels. "],"metadata":{"id":"WtU5GEDETgWF"}},{"cell_type":"code","source":["import torch\n","from torch import nn\n","\n","class SEBlock(nn.Module):\n","    \"\"\"\n","    Implementation of the Squeeze-and-Excitation (SE) block proposed in [1].\n","    Parameters\n","    ----------\n","    in_channels : int\n","        Number of channels in the input tensor.\n","    reduction : int, optional, default=16\n","        Reduction ratio to control the intermediate channel dimension.\n","    References\n","    ----------\n","    1. \"`Squeeze-and-Excitation Networks. <https://arxiv.org/abs/1709.01507>`_\" Jie Hu, et al. CVPR 2018.\n","    \"\"\"\n","\n","    def __init__(self, in_channels: int, reduction: int = 16 ) -> None:\n","        super(SEBlock, self).__init__()\n","        out_channels = 1\n","        reduced_channels = in_channels // reduction\n","        self.squeeze = nn.AdaptiveAvgPool2d((1, 1))\n","        self.excitation = nn.Sequential(\n","            nn.Linear(in_channels, reduced_channels),\n","            nn.ReLU(),\n","            nn.Linear(reduced_channels, in_channels),\n","            nn.ReLU(),\n","            nn.Sigmoid())\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        \"\"\"\n","        Parameters\n","        ----------\n","        x : torch.Tensor (batch_size, in_channels, height, width)\n","            Input tensor.\n","        Returns\n","        -------\n","        out : torch.Tensor (batch_size, in_channels, height, width)\n","            Output of the SK convolution layer.\n","        \"\"\"\n","        # x: [b, c, h, w]\n","\n","        z = self.squeeze(x) # eq.2 [b, c, 1, 1]\n","        s = self.excitation(torch.squeeze(z)).unsqueeze(0).unsqueeze(2).unsqueeze(2) # eq.3 [b, c, 1, 1]\n","        out =  x * s # eq. 4 [b, c, h, w]\n","        return out"],"metadata":{"id":"X_mydDHhTfmE","executionInfo":{"status":"ok","timestamp":1678182509469,"user_tz":-180,"elapsed":8879,"user":{"displayName":"Somebody Else","userId":"08803507653978694405"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["features = torch.rand(1, 32, 25, 25)\n","out = SEBlock(32)\n","out(features).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aOHbgJ_HVDnT","outputId":"cc02685e-d0f8-425e-b2ff-ffe16588bd7a","executionInfo":{"status":"ok","timestamp":1678119567741,"user_tz":-180,"elapsed":24,"user":{"displayName":"Somebody Else","userId":"08803507653978694405"}}},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 32, 25, 25])"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["# Selective Kernel (SK) Convolution"],"metadata":{"id":"pn6zgoRbTeHv"}},{"cell_type":"markdown","source":["To enable the neurons to adaptively adjust their RF sizes,\n","we propose an automatic selection operation, “Selective\n","Kernel” (SK) convolution, among multiple kernels with different kernel sizes"],"metadata":{"id":"q9n-ayyPeikO"}},{"cell_type":"code","source":["import torch\n","from torch import nn\n","from typing import List, Optional\n","\n","class SKConv(nn.Module):\n","    \"\"\"\n","    Implementation of the Selective Kernel (SK) Convolution proposed in [1].\n","    Parameters\n","    ----------\n","    in_channels : int\n","        Number of channels in the input tensor.\n","    out_channels : int\n","        Number of channels produced by the convolution.\n","    kernels : List[int], optional, default=[3, 5]\n","        List of kernel sizes for each branch.\n","    reduction : int, optional, default=16\n","        Reduction ratio to control the dimension of \"compact feature\" ``z`` (see eq.4).\n","    L : int, optional, default=32\n","        Minimal value of the dimension of \"compact feature\" ``z`` (see eq.4).\n","    groups : int, optional, default=32\n","        Hyperparameter for ``torch.nn.Conv2d``.\n","    References\n","    ----------\n","    1. \"`Selective Kernel Networks. <https://arxiv.org/abs/1903.06586>`_\" Xiang Li, et al. CVPR 2019.\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: Optional[int] = None,\n","        kernels: List[int] = [3, 5],\n","        reduction: int = 16,\n","        min_channels: int = 32, #  L\n","        groups: int = 32\n","    ) -> None:\n","\n","        super(SKConv, self).__init__()\n","\n","        if out_channels is None:\n","            out_channels = in_channels\n","        self.out_channels = out_channels\n","\n","        self.d = max(in_channels // reduction, min_channels) # eq.4\n","\n","        self.M = len(kernels)\n","\n","        self.convs = nn.ModuleList([\n","                nn.Sequential(nn.Conv2d(in_channels, in_channels, k, groups=in_channels, padding='same'), \n","                              nn.BatchNorm2d(in_channels),\n","                              nn.ReLU())\n","            for k in kernels\n","        ])\n","\n","        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n","\n","        self.fc_z = nn.Sequential(\n","            nn.BatchNorm2d(),\n","            nn.ReLU()\n","        )\n","        self.fc_attn = nn.Linear(...)\n","        self.softmax = nn.Softmax(...)\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        \"\"\"\n","        Parameters\n","        ----------\n","        x : torch.Tensor (batch_size, in_channels, height, width)\n","            Input tensor.\n","        Returns\n","        -------\n","        out : torch.Tensor (batch_size, out_channels, height, width)\n","            Output of the SK convolution layer.\n","        \"\"\"\n","        #Conv2d , AvgPoll, softmax, ReLU, BatchNorm, Linear\n","\n","        # ----- split -----\n","        # x: [b, c, h, w]\n","        feats = torch.stack([conv(x) for conv in self.convs], dim=1)  # [b, M, c, h, w]\n","\n","        # ----- fuse -----\n","        # eq.1\n","        U = torch.sum(feats, dim=1)\n","        # channel-wise statistics, eq.2\n","        s = self.pool(U).squeeze(3).squeeze(2) #s: [b, c]\n","        # compact feature, eq.3\n","        z = self.fc_z(s) # z [b, d]\n","\n","        # ----- select -----\n","        batch_size, out_channels = s.shape\n","\n","        # attention map, eq.5\n","        score = ...  # (batch_size, M * out_channels)\n","        score = ...)  # (batch_size, M, out_channels, 1, 1)\n","        att = ...\n","\n","\n","        # fuse multiple branches, eq.6\n","        out = ...  # (batch_size, out_channels, height, width)\n","        return out"],"metadata":{"id":"q73b0ujBVC6Q","colab":{"base_uri":"https://localhost:8080/","height":134},"executionInfo":{"status":"error","timestamp":1678119567743,"user_tz":-180,"elapsed":21,"user":{"displayName":"Somebody Else","userId":"08803507653978694405"}},"outputId":"cb6c899a-8f3d-402d-f255-c6ec79b8283c"},"execution_count":3,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-b26de29d94aa>\"\u001b[0;36m, line \u001b[0;32m89\u001b[0m\n\u001b[0;31m    score = ...)  # (batch_size, M, out_channels, 1, 1)\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"]}]},{"cell_type":"code","source":["pool = nn.AdaptiveAvgPool2d((1, 1))\n","feats = torch.rand(1, 34*16, 25, 25)\n","out = pool(feats).squeeze(3).squeeze(2)\n","out.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pc7oo7b6qbEc","executionInfo":{"status":"ok","timestamp":1678185802505,"user_tz":-180,"elapsed":242,"user":{"displayName":"Somebody Else","userId":"08803507653978694405"}},"outputId":"80c77aac-6fd9-4d49-b1cb-89d3a9bebd7a"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 544])"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["fc_z = nn.Sequential(\n","            nn.Linear(544, 32),\n","            nn.BatchNorm1d(32),\n","            nn.ReLU()\n","        )"],"metadata":{"id":"dhniLNTAop0q","executionInfo":{"status":"ok","timestamp":1678186421763,"user_tz":-180,"elapsed":256,"user":{"displayName":"Somebody Else","userId":"08803507653978694405"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["feats = torch.rand(1, 544) \n","\n","out = fc_z(feats)\n","out.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":377},"id":"LzIdvmcbxR-t","executionInfo":{"status":"error","timestamp":1678186493187,"user_tz":-180,"elapsed":7,"user":{"displayName":"Somebody Else","userId":"08803507653978694405"}},"outputId":"dceed090-9176-4c6a-b2d7-e22e464be5a7"},"execution_count":48,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-48-6d98e80338f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m544\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc_z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \"\"\"\n\u001b[0;32m--> 171\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2446\u001b[0m         )\n\u001b[1;32m   2447\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2448\u001b[0;31m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2450\u001b[0m     return torch.batch_norm(\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_verify_batch_size\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   2414\u001b[0m         \u001b[0msize_prods\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2415\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_prods\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2416\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected more than 1 value per channel when training, got input size {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 32])"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Kve9WK2_j5oh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XxnKevLvj5_P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = torch.rand(1, 34*16, 25, 25)\n","out = SKConv(34*16).eval()\n","out(features).shape"],"metadata":{"id":"cmcAyPakUdoA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9044b6b2-e4c4-499c-deda-addd61724122"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 544, 25, 25])"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["n = nn.Conv2d(3, 3, kernel_size=3)\n","n.weight.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BNKG8vIKeKNg","outputId":"4ef91f3f-8d8e-4b5f-c037-6bc8b3272d17"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3, 3, 3, 3])"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["n = nn.Conv2d(3, 3, kernel_size=3, groups=3)\n","n.weight.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ph1iTPZda_cB","outputId":"20e9170b-bc34-4e27-cb63-98d450db43b0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3, 1, 3, 3])"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["features = torch.rand(1, 3, 25, 25)\n","n(features).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lZL-49lsbDql","outputId":"7227d95c-c860-4608-dc55-c3cdfd33cfec"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 3, 23, 23])"]},"metadata":{},"execution_count":80}]},{"cell_type":"code","source":[],"metadata":{"id":"xH1GgjM-z3Rv"},"execution_count":null,"outputs":[]}]}